---
layout:     post
title:      "Деревья принятия решений в R"
date:       2015-11-10 22:00:00
author:     "Vasiliy Zemlyanov"
header-img: "img/post-bg-03.jpg"
---

##TODO:
```
Использовать для статьи пост о титанике
```

Дерево принятия решений - средство поддержки принятия решений, использующееся в статистике и анализе данных для прогнозных моделей.

Достоинством деревьев является возможность интерпритировать результат.
Недостатком является `НЕДОСТАТКИ ДЕРЕВЬЕВ`

#Пример дерева

Рассмотрим пример простого дерева для данных об пассажирах Титаника.

<p class="center">
    <img src="/assets/trees/tree_example.png" alt="Tree example" class='center-block'>
</p>

В корне дерева проверяется пол пассажира. Все мужчины при этом определяются как погибшие.
Для выживших пассажиров выпроняется следующая проверка, если пассажир путещевстсовал классом выше 3 - модель определяет его как выжившего.
Среди пассажиров третьего класса выжили пассажири моложе 25 лет. Это досточно простое дерево решений предсказывает выживание пассажира в 75.7% случаев и позволяет сделать выводы о том, какие факторы повлияли на выживание пассажиров Титаника.

#Модель

Данная модель строит дерево на основе разбияния независимых переменных.

Один из сопсобов определить количество разбиений задать `minBucket` параметр, минимальное количестов элементов которое должно попасть в каждое ветвление.
Если `minBucket` будет слишком большим:
Если `minBucket` будет слишком низким:


{% highlight R %}
setwd("F:/Dev/analitics/trees/")
titanic = read.csv("titanic.csv")

str(titanic)
set.seed(3000)

library(caTools)
split = sample.split(titanic$Survived, SplitRatio = 0.7)
Train = subset(titanic, split == TRUE)
Test = subset(titanic, split == FALSE)

#  Установка и загрузка пакетов
install.packages("rpart")
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)

# Строим модель
TitanicTree = rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare,
                    data = Train, method = "class",
                    control=rpart.control(minbucket = 25))

# Изображение дерева
prp(TitanicTree)

# Предсказания
PredictCART = predict(TitanicTree, newdata = Test, type="class")

# Определяем точность
table(Test$Survived, PredictCART)
{% endhighlight %}

##Как выбрать количество ветвлений

##ROC кривая

{% highlight R %}
# Plot ROC curve
library(ROCR)
PredictROC = predict(TitanicTree, newdata = Test)
pref = prediction(PredictROC[,2], Test$Survived)
perf = performance(pref, "tpr", "fpr")
plot(perf)
{% endhighlight %}

#Random forest

Этот метод был разработан для улучшения предсказывающих качеств деревьев принятия решений и работает на основе построение большого количества деревьев.
Ценой за улучшение предсказывающих способностей является уменьшение интерпритируемости результатов.

Для того, чтобы сделать предсказание с помощью `Random forest` каждое дерево *голосует* за результат и мы выбираем результат модели по большинству голосов.

Каждое дерево строится из `badged or bootstrapped` подмножества данных с повторениями.

Параметры Random Forest:

- Минимальное количество наблюдений в подмножестве (`nodesize`)
- Количество деревьев (`ntree`)

## Random forest в R

{% highlight R %}
### Random forest example

# install package
install.packages("randomForest")
library(randomForest)

# Building model
# Outcome variable should be a factor
Train$Survived = as.factor(Train$Survived)
Test$Survived = as.factor(Test$Survived)

Train$Age[is.na(Train$Age)] <- median(Train$Age, na.rm=TRUE)

# nodesize - number of items in bucket; ntree - number of trees to build
TrainForest = randomForest(Survived ~ Pclass + Sex + Age,
                             data=Train, nodesize=25, ntree=200)

# Predicitons
PredictForest = predict(TrainForest, newdata = Test)

# Confusion matrix
table(Test$Survived, PredictForest)
(40 + 75) / (40 + 37 + 18 + 75)
{% endhighlight %}

##Кросс валидация (K-folds Cross-Validation)

(имеет смысл использовать для `random tree`, но не для `random forest`, причиной является то, что `random forest` не так критичен параметрам и сложнее поддается переобучению)
Если `minbucket` слишком мал возможен `overfitting`,
если `minbucket` слишком большой модель может оказатсья слишком простой и не соответствовать реальным данным.

Разобьем тренировочные данные на 5 частей (`folds`).
Используя `k-1` folds для тренировки модели и протестируем на оставшемся fold-e
Повторим для всех значений `k`.

Для каждого значения k и для каждого fold вычислим точность модели.
По оси x выставим значение параметра, а по оси y точность модели. И построим кривые для каждого fold-a.

## Кросс валидация в R

В R за `minbucket` отвечает параметр `cp`

{% highlight R %}
# TODO: Протестировать этот код в R
# Устанавливаем необходимый пакет
install.packages("caret")
install.packages("e1071")
library(caret)
library(e1071)

# method="cv" - использовть кросс-валидацию
# number=10 - использовать 10 фолдов
fitControl = trainControl(method="cv", number=10)
cartGrid = expand.grid(.cp=(1:50)*0.01)

# CrossValidation
train(Reverse ~ Circuit + Issue + Petitioner + ..., data=Train, method="rpart",
    trControl=fitControl, tuneGrid=cartGrid)

# Полученный cp необходимо использовать в функции rpart в качестве параметра
# control=rpart.control(cp=)  
{% endhighlight %}