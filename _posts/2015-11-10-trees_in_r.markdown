---
layout:     post
title:      "Деревья принятия решений в R"
date:       2015-11-10 22:00:00
author:     "Vasiliy Zemlyanov"
header-img: "img/post-bg-03.jpg"
---

##TODO:
```
Использовать для статьи пост о титанике
```

Дерево принятия решений - средство поддержки принятия решений, использующееся в статистике и анализе данных для прогнозных моделей. Структура дерева представляет собой «листья» и «ветки».

Достоинством деревьев является возможность интерпритировать результат.

#Модель
Данная модель строит дерево на основе разбияния независимых переменных.

##Картинка с примером дерева

##Как выбрать количество ветвлений
Один из сопсобов определить количество разбиений - задать `minBucket` параметр, минимальное количестов элементов которое должно попасть в каждое ветвление.
Если `minBucket` будет слишком большим:
Если `minBucket` будет слишком низким:

##ROC кривая

{% highlight R %}
# Backup source from R
setwd("F:/Dev/analitics/trees/")
stevens = read.csv("stevens.csv")

str(stevens)
set.seed(3000)

library(caTools)
split = sample.split(stevens$Revers, SplitRatio = 0.7)
Train = subset(stevens, split == TRUE)
Test = subset(stevens, split == FALSE)

#  Installing package 
install.packages("rpart")
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)

#  Building model
StevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent +
                      LowerCourt + Unconst, data = Train, method = "class",
                    control=rpart.control(minbucket = 25))

#  Plot tree
prp(StevensTree)

# Predicitons
PredictCART = predict(StevensTree, newdata = Test, type="class")

# Compute accurasy
table(Test$Reverse, PredictCART)

# Plot ROC curve
library(ROCR)
PredictROC = predict(StevensTree, newdata = Test)
pref = prediction(PredictROC[,2], Test$Reverse)
perf = performance(pref, "tpr", "fpr")
plot(perf)
{% endhighlight %}

#Random forest
Этот метод был разработан для улучшения предсказывающих качеств деревьев принятия решений и работает на основе построение большого количества деревьев.
Ценой за улучшение предсказывающих способностей является уменьшение интерпритируемости результатов.

Для того, чтобы сделать предсказание с помощью `Random forest` каждое дерево *голосует* за результат и мы выбираем результат модели по большинству голосов.

Каждое дерево строится из `badged or bootstrapped` подмножества данных с повторениями.

Параметры Random Forest:

- Минимальное количество наблюдений в подмножестве (`nodesize`)
- Количество деревьев (`ntree`)

## Random forest в R

{% highlight R %}
### Random forest example

# install package
install.packages("randomForest")
library(randomForest)

# Building model
# Outcome variable should be a factor
Train$Reverse = as.factor(Train$Reverse)
Test$Reverse = as.factor(Test$Reverse)

# nodesize - number of items in bucket; ntree - number of trees to build
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst,
                             data=Train, nodesize=25, ntree=200)

# Predicitons
PredictForest = predict(StevensForest, newdata = Test)

# Confusion matrix
table(Test$Reverse, PredictForest)
(40 + 75) / (40 + 37 + 18 + 75)
{% endhighlight %}

##Кросс валидация (K-folds Cross-Validation)

(имеет смысл использовать для `random tree`, но не для `random forest`, причиной является то, что `random forest` не так критичен параметрам и сложнее поддается переобучению)
Если `minbucket` слишком мал возможен `overfitting`,
если `minbucket` слишком большой модель может оказатсья слишком простой и не соответствовать реальным данным.

Разобьем тренировочные данные на 5 частей (`folds`).
Используя `k-1` folds для тренировки модели и протестируем на оставшемся fold-e
Повторим для всех значений `k`.

Для каждого значения k и для каждого fold вычислим точность модели.
По оси x выставим значение параметра, а по оси y точность модели. И построим кривые для каждого fold-a.

## Кросс валидация в R

{% highlight R %}
# TODO: Протестировать этот код в R
# Устанавливаем необходимый пакет
install.packages("caret")
install.packages("e1071")
library(caret)
library(e1071)

# method="cv" - использовть кросс-валидацию
# number=10 - использовать 10 фолдов
fitControl = trainControl(method="cv", number=10)
cartGrid = expand.grid(.cp=(1:50)*0.01)

# CrossValidation
train(Reverse ~ Circuit + Issue + Petitioner + ..., data=Train, method="rpart",
    trControl=fitControl, tuneGrid=cartGrid)

# Полученный cp необходимо использовать в функции rpart в качестве параметра
# control=rpart.control(cp=)  
{% endhighlight %}